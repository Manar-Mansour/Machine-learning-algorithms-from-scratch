{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 111\n",
      "Test set: 39\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-virginica', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "Accuracy: 94.87179487179486%\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import random \n",
    "import math\n",
    "import operator\n",
    "\n",
    "'''\n",
    "The loadDataset function does the following: \n",
    "1- Reads the dataset file and parses it into a list of lines (dataset examples).\n",
    "2- Converts the numbers in each example from string type to float type to be used in distance calculations\n",
    "3- Splits the examples randomly into training and test examples according to a specified split ratio\n",
    "'''  \n",
    "def loadDataset(filename, split_ratio, trainingSet=[] , testSet=[]):\n",
    "\twith open(filename, 'r') as csvfile:\n",
    "\t    lines = csv.reader(csvfile)\n",
    "\t    dataset = list(lines)\n",
    "\t    for x in range(len(dataset)-1):\n",
    "\t        for y in range(4):\n",
    "\t            dataset[x][y] = float(dataset[x][y])\n",
    "\t        if random.random() < split_ratio:\n",
    "\t            trainingSet.append(dataset[x])\n",
    "\t        else:\n",
    "\t            testSet.append(dataset[x])\n",
    "                \n",
    "'''\n",
    "In the KNN algorithm we need to do the following: \n",
    "1- Compute the distance between every test example in the test set and all the training examples.\n",
    "2- For a given test example, we sort all the calculated distances in an ascending order and choose the \"k\" least \n",
    "distances which correspond to the k nearst neighbors to the given test example (i.e. the training examples that \n",
    "most similar to this test example.\n",
    "3- After finding the k-nearest neighbors, we make a vote or a poll where we go over the nearst neighbors and collect\n",
    "their labels then we assign the most common label to the test example in question.\n",
    "'''\n",
    "#The function that calculates the Euclidean distance between every test example and all the training examples\n",
    "def euclideanDistance(instance1, instance2, length):\n",
    "\tdistance = 0\n",
    "\tfor x in range(length):\n",
    "\t\tdistance += pow((instance1[x] - instance2[x]), 2)\n",
    "\treturn math.sqrt(distance)\n",
    " \n",
    "#The function that finds the k-nearest neighbors to a certain test example\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "\tdistances = []\n",
    "\tlength = len(testInstance)-1\n",
    "\tfor x in range(len(trainingSet)):\n",
    "\t\tdist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "\t\tdistances.append((trainingSet[x], dist)) #making a list with every training example and its distance from the test example at hand\n",
    "\tdistances.sort(key=operator.itemgetter(1)) #sorting the list of training examples ascendingly according to their distance from the test example\n",
    "\tneighbors = []\n",
    "\tfor x in range(k):\n",
    "\t\tneighbors.append(distances[x][0]) #choosing the k most similar training examples to our test example (i.e. selecting the k-nearest neighbors)\n",
    "\treturn neighbors\n",
    " \n",
    "def getResponse(neighbors):\n",
    "\tclassVotes = {}\n",
    "\tfor x in range(len(neighbors)):\n",
    "\t\tresponse = neighbors[x][-1] #recording the label of every training example in the k-nearest neighbors (the label is the last element and thus it is accessed by [-1] )\n",
    "     #collecting the vote of every neighbor in a dictionary where the labels are the keys and the votes are the values of those keys\n",
    "\t\tif response in classVotes:\n",
    "\t\t\tclassVotes[response] += 1 \n",
    "\t\telse:\n",
    "\t\t\tclassVotes[response] = 1\n",
    "\tsortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True) #sort the votes ascendingly \n",
    "\treturn sortedVotes[0][0] #choose the highest vote (i.e. the most common label in the neighbors)\n",
    " \n",
    "#calculate the accuracy of the KNN classifier    \n",
    "def getAccuracy(testSet, predictions):\n",
    "\tcorrect = 0\n",
    "\tfor x in range(len(testSet)):\n",
    "\t\tif testSet[x][-1] == predictions[x]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn (correct/float(len(testSet))) * 100.0\n",
    "\t\n",
    "def main():\n",
    "\t# prepare data\n",
    "\ttrainingSet=[]\n",
    "\ttestSet=[]\n",
    "\tsplit_ratio = 0.7\n",
    "\tloadDataset('iris.data', split_ratio, trainingSet, testSet)\n",
    "\tprint(\"Train set: \" + repr(len(trainingSet))) \n",
    "\tprint(\"Test set: \" + repr(len(testSet))) \n",
    "\t# generate predictions\n",
    "\tpredictions=[]\n",
    "\tk = 3\n",
    "\tfor x in range(len(testSet)):\n",
    "\t\tneighbors = getNeighbors(trainingSet, testSet[x], k)\n",
    "\t\tresult = getResponse(neighbors)\n",
    "\t\tpredictions.append(result)\n",
    "\t\tprint('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n",
    "\taccuracy = getAccuracy(testSet, predictions)\n",
    "\tprint('Accuracy: ' + repr(accuracy) + '%')\n",
    "\t\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
